{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Leaf_dataset.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNdHWYIAPzyE5P9MJi31JWP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Porubova/images/blob/master/Leaf_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOZJvUuD_jif",
        "colab_type": "text"
      },
      "source": [
        "Leafsnap (http://leafsnap.com) is an electronic field guide for identifying tree\n",
        "species from photos of their leaves. It was jointly created by computer\n",
        "scientists from Columbia University and the University of Maryland, and\n",
        "botanists from the Smithsonian Institution in Washington, DC.\n",
        "The dataset covers all 185 tree species from the Northeastern United States.\n",
        "\n",
        "Ref: \n",
        "\n",
        "Neeraj Kumar, Peter N. Belhumeur, Arijit Biswas, David W. Jacobs, W. John Kress, Ida Lopez, JoÃ£o V. B. Soares,\n",
        "\"Leafsnap: A Computer Vision System for Automatic Plant Species Identification,\"\n",
        "Proceedings of the 12th European Conference on Computer Vision (ECCV),\n",
        "October 2012."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVnqQep2tfzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#donload libraries\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCAR5Lrsrclw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#donload dataset from source\n",
        "!wget http://leafsnap.com/static/dataset/leafsnap-dataset.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHabPhRBr7Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extract tar archieve \n",
        "!tar -xf leafsnap-dataset.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQBP_Hd1u1Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create data folder for merged lab and field images\n",
        "if not os.path.exists(\"data\"):\n",
        "  os.mkdir('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06aAv4i8ANm4",
        "colab_type": "text"
      },
      "source": [
        "The images splietted into two categories:\n",
        "\n",
        "1. 23147 Lab images, consisting of high-quality images taken of pressed leaves, from the Smithsonian collection. These images appear in controlled backlit and front-lit versions, with several samples per species.\n",
        "\n",
        "2. 7719 Field images, consisting of \"typical\" images taken by mobile devices 2.2(iPhones mostly) in outdoor environments. These images contain varying amounts of blur, noise, illumination patterns, shadows, etc.\n",
        "\n",
        "I merged them into one folder, separated by names.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfwTBhCgwvPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Easy and elegant merge of two folders with subfolders and files https://lukelogbook.tech/2018/01/25/merging-two-folders-in-python/\n",
        "\n",
        "def mergefolders(root_src_dir, root_dst_dir):\n",
        "    for src_dir, dirs, files in os.walk(root_src_dir):\n",
        "        dst_dir = src_dir.replace(root_src_dir, root_dst_dir, 1)\n",
        "        if not os.path.exists(dst_dir):\n",
        "            os.makedirs(dst_dir)\n",
        "        for file_ in files:\n",
        "            src_file = os.path.join(src_dir, file_)\n",
        "            dst_file = os.path.join(dst_dir, file_)\n",
        "            if os.path.exists(dst_file):\n",
        "                os.remove(dst_file)\n",
        "            shutil.copy(src_file, dst_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypbB5ZAIw0v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergefolders('/content/dataset/images/field','data')\n",
        "mergefolders('/content/dataset/images/lab','data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf5EHNt_yP41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.make_archive('leaf_data', 'zip', 'data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VebgEpBZBMXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = os.listdir('/content/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4xRdBoHCAFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of classes per leaf dataset:\",len(classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMESFcjn1Kn1",
        "colab_type": "text"
      },
      "source": [
        "let's print number of images for the first 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeWQJ5oXCTwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for cla in classes[0:10]:\n",
        "  print (cla, \": number of images \", len(os.listdir('data/'+cla)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4jJ9tuz1XQY",
        "colab_type": "text"
      },
      "source": [
        "Next, we can dicplay random lab and field images to see how they differ in size and quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0knVqHXpOoFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper display function\n",
        "def imshow(img):\n",
        "    img = mpimg.imread(img)\n",
        "    plt.imshow(img)\n",
        "#random images from dataset\n",
        "random_images =['/content/data/abies_nordmanniana/13291651129246.jpg', \n",
        "         '/content/data/abies_nordmanniana/ny1057-01-3.jpg', \n",
        "         '/content/data/betula_lenta/1248106459_0000.jpg',\n",
        "         '/content/data/betula_lenta/wb1193-06-4.jpg',\n",
        "         '/content/data/juglans_nigra/1249316300_0002.jpg',\n",
        "         '/content/data/juglans_nigra/pi2116-03-3.jpg',\n",
        "         '/content/data/nyssa_sylvatica/12992004532153.jpg',\n",
        "         '/content/data/nyssa_sylvatica/ny1128-02-4.jpg',\n",
        "         '/content/data/quercus_montana/13292231174757.jpg',\n",
        "         '/content/data/quercus_montana/pi0037-03-4.jpg',\n",
        "         '/content/data/quercus_montana/pi0037-03-2.jpg']        \n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(20,4))\n",
        "plot_size=10\n",
        "for i in np.arange(plot_size):\n",
        "    ax = fig.add_subplot(2, plot_size/2, i+1, xticks=[], yticks=[])\n",
        "    imshow(random_images[i])\n",
        "    ax.set_title(random_images[i].split('/')[-2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn4LlcvC4As7",
        "colab_type": "text"
      },
      "source": [
        "And print dimention of these images. they are represented in H, W, C order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5dP7nW62MxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in np.arange(plot_size):  \n",
        "   =  mpimg.imread(random_images[i])\n",
        "  print(X_0.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PHl8zRN1p_m",
        "colab_type": "text"
      },
      "source": [
        "As it can be seen, the images are different in qualiity and size. we can use some pre-processing technisuses on training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYR7uhhJ42z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}